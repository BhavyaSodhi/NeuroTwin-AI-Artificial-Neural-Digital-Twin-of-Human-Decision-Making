{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "def simulate_human_decision(risk, time_pressure, reward, mood, prev_loss):\n",
        "    score = 0\n",
        "\n",
        "    score += reward * 0.6\n",
        "    score -= risk * 0.7\n",
        "    score -= prev_loss * 0.8\n",
        "    score -= time_pressure * 0.3\n",
        "    score += (1 - mood) * 0.4  # calm mood helps\n",
        "\n",
        "    noise = random.uniform(-0.2, 0.2)\n",
        "    score += noise\n",
        "\n",
        "    return 1 if score > 0.1 else 0\n",
        "\n",
        "def generate_dataset(samples=5000):\n",
        "    data = []\n",
        "\n",
        "    prev_decision = 0\n",
        "    prev_loss = 0\n",
        "\n",
        "    for _ in range(samples):\n",
        "        risk = np.random.rand()\n",
        "        time_pressure = np.random.rand()\n",
        "        reward = np.random.rand()\n",
        "        mood = np.random.rand()  # 0 = calm, 1 = stressed\n",
        "        reaction_time = np.random.uniform(0.5, 4.0)\n",
        "\n",
        "        decision = simulate_human_decision(\n",
        "            risk, time_pressure, reward, mood, prev_loss\n",
        "        )\n",
        "\n",
        "        prev_loss = 1 if decision == 0 and reward > 0.6 else 0\n",
        "\n",
        "        data.append([\n",
        "            risk, time_pressure, reward, mood,\n",
        "            prev_loss, reaction_time, decision\n",
        "        ])\n",
        "\n",
        "    columns = [\n",
        "        \"risk\", \"time_pressure\", \"reward\",\n",
        "        \"mood\", \"previous_loss\",\n",
        "        \"reaction_time\", \"decision\"\n",
        "    ]\n",
        "\n",
        "    df = pd.DataFrame(data, columns=columns)\n",
        "    df.to_csv(\"neurotwin_data.csv\", index=False)\n",
        "    print(\"Dataset generated successfully!\")\n",
        "\n",
        "generate_dataset()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EMHM4ZwuVnQz",
        "outputId": "b4d655eb-98cc-4f11-8922-b6c280217738"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset generated successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class NeuroTwin(nn.Module):\n",
        "    def __init__(self, input_size=6, hidden_size=64):\n",
        "        super(NeuroTwin, self).__init__()\n",
        "\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=input_size,\n",
        "            hidden_size=hidden_size,\n",
        "            batch_first=True\n",
        "        )\n",
        "\n",
        "        self.decision_head = nn.Linear(hidden_size, 1)\n",
        "        self.confidence_head = nn.Linear(hidden_size, 1)\n",
        "\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        lstm_out, _ = self.lstm(x)\n",
        "        last_state = lstm_out[:, -1, :]\n",
        "\n",
        "        decision = self.sigmoid(self.decision_head(last_state))\n",
        "        confidence = self.sigmoid(self.confidence_head(last_state))\n",
        "\n",
        "        return decision, confidence\n"
      ],
      "metadata": {
        "id": "lLwVqM5sV1tK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv(\"neurotwin_data.csv\")\n",
        "\n",
        "X = df.iloc[:, :-1].values\n",
        "y = df.iloc[:, -1].values\n",
        "\n",
        "# Convert to sequences\n",
        "sequence_length = 5\n",
        "X_seq_list, y_seq_list = [], []\n",
        "\n",
        "for i in range(len(X) - sequence_length):\n",
        "    X_seq_list.append(X[i:i+sequence_length])\n",
        "    y_seq_list.append(y[i+sequence_length])\n",
        "\n",
        "# Convert lists to numpy arrays first to avoid UserWarning and improve performance\n",
        "X_seq = torch.tensor(np.array(X_seq_list), dtype=torch.float32)\n",
        "y_seq = torch.tensor(np.array(y_seq_list), dtype=torch.float32).unsqueeze(1)\n",
        "\n",
        "model = NeuroTwin()\n",
        "criterion = torch.nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(20):\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    decision, confidence = model(X_seq)\n",
        "    loss = criterion(decision, y_seq)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "torch.save(model.state_dict(), \"neurotwin_model.pth\")\n",
        "print(\"Model trained & saved!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0AyBKunQV6Eu",
        "outputId": "7fad1cc0-88aa-467c-e985-7d5b55287891"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.7096\n",
            "Epoch 2, Loss: 0.7030\n",
            "Epoch 3, Loss: 0.6967\n",
            "Epoch 4, Loss: 0.6907\n",
            "Epoch 5, Loss: 0.6849\n",
            "Epoch 6, Loss: 0.6792\n",
            "Epoch 7, Loss: 0.6738\n",
            "Epoch 8, Loss: 0.6685\n",
            "Epoch 9, Loss: 0.6634\n",
            "Epoch 10, Loss: 0.6584\n",
            "Epoch 11, Loss: 0.6535\n",
            "Epoch 12, Loss: 0.6487\n",
            "Epoch 13, Loss: 0.6441\n",
            "Epoch 14, Loss: 0.6396\n",
            "Epoch 15, Loss: 0.6352\n",
            "Epoch 16, Loss: 0.6311\n",
            "Epoch 17, Loss: 0.6271\n",
            "Epoch 18, Loss: 0.6234\n",
            "Epoch 19, Loss: 0.6201\n",
            "Epoch 20, Loss: 0.6172\n",
            "Model trained & saved!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "model = NeuroTwin()\n",
        "model.load_state_dict(torch.load(\"neurotwin_model.pth\"))\n",
        "model.eval()\n",
        "\n",
        "# Sample scenario\n",
        "sample = np.array([\n",
        "    [0.8, 0.2, 0.9, 0.3, 0, 1.2]\n",
        "] * 5)\n",
        "\n",
        "sample = torch.tensor(sample, dtype=torch.float32).unsqueeze(0)\n",
        "\n",
        "decision, confidence = model(sample)\n",
        "\n",
        "print(\"Predicted Decision:\", \"ACCEPT\" if decision.item() > 0.5 else \"REJECT\")\n",
        "print(\"Confidence:\", round(confidence.item(), 2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VaCrg7OoWKWY",
        "outputId": "ec21dc29-68a4-4d66-f3fc-c0a96a0b6404"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Decision: REJECT\n",
            "Confidence: 0.54\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def explain_decision(input_data):\n",
        "    explanations = []\n",
        "\n",
        "    if input_data[\"risk\"] > 0.7:\n",
        "        explanations.append(\"High risk reduced acceptance\")\n",
        "\n",
        "    if input_data[\"reward\"] > 0.7:\n",
        "        explanations.append(\"High reward increased motivation\")\n",
        "\n",
        "    if input_data[\"mood\"] > 0.6:\n",
        "        explanations.append(\"Stress affected confidence\")\n",
        "\n",
        "    if input_data[\"previous_loss\"] == 1:\n",
        "        explanations.append(\"Past loss caused hesitation\")\n",
        "\n",
        "    return explanations\n"
      ],
      "metadata": {
        "id": "KdUUAIS1WVtf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "# Load trained model\n",
        "model = NeuroTwin()\n",
        "model.load_state_dict(torch.load(\"neurotwin_model.pth\", map_location=\"cpu\"))\n",
        "model.eval()\n",
        "\n",
        "# Explanation logic (human-readable)\n",
        "def explain_decision(risk, time_pressure, reward, mood, prev_loss):\n",
        "    reasons = []\n",
        "\n",
        "    if risk > 0.7:\n",
        "        reasons.append(\"High risk reduced willingness to accept\")\n",
        "\n",
        "    if reward > 0.7:\n",
        "        reasons.append(\"High reward increased motivation\")\n",
        "\n",
        "    if time_pressure > 0.6:\n",
        "        reasons.append(\"Time pressure increased stress\")\n",
        "\n",
        "    if mood > 0.6:\n",
        "        reasons.append(\"Stressed mood lowered confidence\")\n",
        "\n",
        "    if prev_loss == 1:\n",
        "        reasons.append(\"Past loss caused hesitation\")\n",
        "\n",
        "    if not reasons:\n",
        "        reasons.append(\"Balanced conditions led to a neutral decision\")\n",
        "\n",
        "    return \" ‚Ä¢ \" + \"\\n ‚Ä¢ \".join(reasons)\n",
        "\n",
        "# Prediction function\n",
        "def neurotwin_predict(risk, time_pressure, reward, mood, prev_loss, reaction_time):\n",
        "    # Create 5-step decision memory (LSTM sequence)\n",
        "    sample = np.array([\n",
        "        [risk, time_pressure, reward, mood, prev_loss, reaction_time]\n",
        "    ] * 5)\n",
        "\n",
        "    sample = torch.tensor(sample, dtype=torch.float32).unsqueeze(0)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        decision, confidence = model(sample)\n",
        "\n",
        "    decision_label = \"ACCEPT ‚úÖ\" if decision.item() > 0.5 else \"REJECT ‚ùå\"\n",
        "    confidence_score = round(confidence.item() * 100, 2)\n",
        "\n",
        "    explanation = explain_decision(\n",
        "        risk, time_pressure, reward, mood, prev_loss\n",
        "    )\n",
        "\n",
        "    return decision_label, f\"{confidence_score}%\", explanation\n",
        "\n",
        "# Gradio UI\n",
        "with gr.Blocks(title=\"NeuroTwin AI ‚Äì Human Decision Digital Twin\") as demo:\n",
        "    gr.Markdown(\"\"\"\n",
        "    # üß† NeuroTwin AI\n",
        "    ### Artificial Neural Digital Twin of Human Decision-Making\n",
        "\n",
        "    This system learns **how a human decides**, not just *what* they decide.\n",
        "    \"\"\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            risk = gr.Slider(0, 1, value=0.5, label=\"Risk Level\")\n",
        "            time_pressure = gr.Slider(0, 1, value=0.5, label=\"Time Pressure\")\n",
        "            reward = gr.Slider(0, 1, value=0.5, label=\"Reward Value\")\n",
        "            mood = gr.Slider(0, 1, value=0.5, label=\"Stress Level (Mood)\")\n",
        "            prev_loss = gr.Radio([0, 1], label=\"Previous Loss\", value=0)\n",
        "            reaction_time = gr.Slider(0.5, 4.0, value=1.5, label=\"Reaction Time (seconds)\")\n",
        "\n",
        "            predict_btn = gr.Button(\"üß† Predict Decision\")\n",
        "\n",
        "        with gr.Column():\n",
        "            decision_out = gr.Textbox(label=\"Predicted Decision\")\n",
        "            confidence_out = gr.Textbox(label=\"Confidence Level\")\n",
        "            explanation_out = gr.Textbox(\n",
        "                label=\"Decision Explanation\",\n",
        "                lines=6\n",
        "            )\n",
        "\n",
        "    predict_btn.click(\n",
        "        neurotwin_predict,\n",
        "        inputs=[\n",
        "            risk, time_pressure, reward,\n",
        "            mood, prev_loss, reaction_time\n",
        "        ],\n",
        "        outputs=[\n",
        "            decision_out,\n",
        "            confidence_out,\n",
        "            explanation_out\n",
        "        ]\n",
        "    )\n",
        "\n",
        "demo.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        },
        "id": "eYx5ZpNBWodZ",
        "outputId": "c6d8085e-c7a1-49f5-8e3f-8ee836305522"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://7d5a5c5822b569db1b.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://7d5a5c5822b569db1b.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import torch\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "MODEL_DIR = \"user_profiles\"\n",
        "BASE_MODEL_PATH = \"neurotwin_model.pth\"\n",
        "\n",
        "os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "\n",
        "# Load or create user-specific model\n",
        "def load_user_model(username):\n",
        "    model = NeuroTwin()\n",
        "    user_model_path = f\"{MODEL_DIR}/{username}.pth\"\n",
        "\n",
        "    if os.path.exists(user_model_path):\n",
        "        model.load_state_dict(torch.load(user_model_path, map_location=\"cpu\"))\n",
        "    else:\n",
        "        model.load_state_dict(torch.load(BASE_MODEL_PATH, map_location=\"cpu\"))\n",
        "        torch.save(model.state_dict(), user_model_path)\n",
        "\n",
        "    model.eval()\n",
        "    return model, user_model_path\n",
        "\n",
        "# Explanation engine\n",
        "def explain(risk, reward, mood, prev_loss):\n",
        "    reasons = []\n",
        "    if risk > 0.7:\n",
        "        reasons.append(\"High risk caused hesitation\")\n",
        "    if reward > 0.7:\n",
        "        reasons.append(\"High reward encouraged acceptance\")\n",
        "    if mood > 0.6:\n",
        "        reasons.append(\"Stress reduced confidence\")\n",
        "    if prev_loss == 1:\n",
        "        reasons.append(\"Past loss influenced decision\")\n",
        "\n",
        "    return \"\\n\".join(reasons) if reasons else \"Balanced conditions\"\n",
        "\n",
        "# Prediction function\n",
        "def predict(username, risk, time_pressure, reward, mood, prev_loss, reaction_time):\n",
        "    if not username:\n",
        "        return \"‚ùå Enter username\", \"\", \"\"\n",
        "\n",
        "    model, _ = load_user_model(username)\n",
        "\n",
        "    seq = np.array([\n",
        "        [risk, time_pressure, reward, mood, prev_loss, reaction_time]\n",
        "    ] * 5)\n",
        "\n",
        "    seq = torch.tensor(seq, dtype=torch.float32).unsqueeze(0)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        decision, confidence = model(seq)\n",
        "\n",
        "    label = \"ACCEPT ‚úÖ\" if decision.item() > 0.5 else \"REJECT ‚ùå\"\n",
        "    conf = f\"{round(confidence.item()*100,2)}%\"\n",
        "    explanation = explain(risk, reward, mood, prev_loss)\n",
        "\n",
        "    return label, conf, explanation\n",
        "\n",
        "# Online learning (user brain evolves)\n",
        "def train_user(username, risk, time_pressure, reward, mood, prev_loss, reaction_time, true_decision):\n",
        "    model, path = load_user_model(username)\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)\n",
        "    loss_fn = torch.nn.BCELoss()\n",
        "\n",
        "    seq = np.array([\n",
        "        [risk, time_pressure, reward, mood, prev_loss, reaction_time]\n",
        "    ] * 5)\n",
        "\n",
        "    seq = torch.tensor(seq, dtype=torch.float32).unsqueeze(0)\n",
        "    target = torch.tensor([[true_decision]], dtype=torch.float32)\n",
        "\n",
        "    decision, _ = model(seq)\n",
        "    loss = loss_fn(decision, target)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    torch.save(model.state_dict(), path)\n",
        "    return \"‚úÖ User cognitive profile updated!\"\n",
        "\n",
        "# Gradio UI\n",
        "with gr.Blocks(title=\"NeuroTwin AI ‚Äì Multi-User Cognitive Profiles\") as demo:\n",
        "    gr.Markdown(\"\"\"\n",
        "    # üß† NeuroTwin AI\n",
        "    ## Multi-User Cognitive Digital Twin System\n",
        "\n",
        "    Each user has a **personal neural brain** that learns how *they* decide.\n",
        "    \"\"\")\n",
        "\n",
        "    username = gr.Textbox(label=\"üë§ Username (New or Existing)\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            risk = gr.Slider(0,1,0.5,label=\"Risk Level\")\n",
        "            time_pressure = gr.Slider(0,1,0.5,label=\"Time Pressure\")\n",
        "            reward = gr.Slider(0,1,0.5,label=\"Reward Value\")\n",
        "            mood = gr.Slider(0,1,0.5,label=\"Stress Level\")\n",
        "            prev_loss = gr.Radio([0,1],label=\"Previous Loss\",value=0)\n",
        "            reaction_time = gr.Slider(0.5,4.0,1.5,label=\"Reaction Time\")\n",
        "\n",
        "        with gr.Column():\n",
        "            decision_out = gr.Textbox(label=\"Predicted Decision\")\n",
        "            confidence_out = gr.Textbox(label=\"Confidence\")\n",
        "            explanation_out = gr.Textbox(label=\"Explanation\", lines=6)\n",
        "\n",
        "    predict_btn = gr.Button(\"üß† Predict Decision\")\n",
        "    predict_btn.click(\n",
        "        predict,\n",
        "        inputs=[\n",
        "            username, risk, time_pressure, reward,\n",
        "            mood, prev_loss, reaction_time\n",
        "        ],\n",
        "        outputs=[decision_out, confidence_out, explanation_out]\n",
        "    )\n",
        "\n",
        "    gr.Markdown(\"### üß¨ Train User Brain (Online Learning)\")\n",
        "    true_decision = gr.Radio([0,1], label=\"Actual User Decision (0=Reject, 1=Accept)\")\n",
        "    train_btn = gr.Button(\"üîÅ Update Cognitive Profile\")\n",
        "\n",
        "    train_btn.click(\n",
        "        train_user,\n",
        "        inputs=[\n",
        "            username, risk, time_pressure, reward,\n",
        "            mood, prev_loss, reaction_time, true_decision\n",
        "        ],\n",
        "        outputs=gr.Textbox()\n",
        "    )\n",
        "\n",
        "demo.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        },
        "id": "WLruPQNrXUqv",
        "outputId": "5703fda4-4144-4ebd-da21-0e7a20285f90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://3557cf2a16623be82a.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://3557cf2a16623be82a.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def extract_brain_vector(model):\n",
        "    \"\"\"Flatten neural weights into 1 vector\"\"\"\n",
        "    weights = []\n",
        "    for param in model.parameters():\n",
        "        weights.append(param.detach().cpu().numpy().flatten())\n",
        "    return np.concatenate(weights)\n",
        "\n",
        "# üß† Brain Drift\n",
        "def brain_drift(old_vec, new_vec):\n",
        "    return np.linalg.norm(new_vec - old_vec)\n",
        "\n",
        "# üß† Cognitive Similarity\n",
        "def cognitive_similarity(vec1, vec2):\n",
        "    return cosine_similarity([vec1], [vec2])[0][0]\n",
        "\n",
        "# üß† Personality Clustering\n",
        "def cluster_users(brain_vectors, n_clusters=3):\n",
        "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
        "    labels = kmeans.fit_predict(brain_vectors)\n",
        "    return labels\n"
      ],
      "metadata": {
        "id": "BsgPr4AIYUvD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class NeuroTwin(nn.Module):\n",
        "    def __init__(self, input_size=6, hidden_size=64):\n",
        "        super().__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
        "        self.decision = nn.Linear(hidden_size, 1)\n",
        "        self.confidence = nn.Linear(hidden_size, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x)\n",
        "        h = out[:, -1, :]\n",
        "        return self.sigmoid(self.decision(h)), self.sigmoid(self.confidence(h))\n"
      ],
      "metadata": {
        "id": "D80bO94RYiAZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "model = NeuroTwin()\n",
        "torch.save(model.state_dict(), \"neurotwin_model.pth\")\n",
        "print(\"‚úÖ Base model created successfully\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbAF6GoJZzqt",
        "outputId": "da037bb5-391d-48ab-8248-3ba0db676682"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Base model created successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib\n",
        "matplotlib.use(\"Agg\")\n",
        "\n",
        "import gradio as gr\n",
        "import torch, os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# ================= CONFIG =================\n",
        "BASE_MODEL = \"neurotwin_model.pth\"\n",
        "USER_DIR = \"user_profiles\"\n",
        "os.makedirs(USER_DIR, exist_ok=True)\n",
        "\n",
        "# ================= STATE =================\n",
        "def init_state():\n",
        "    return pd.DataFrame(columns=[\n",
        "        \"user_id\",\"name\",\"age\",\n",
        "        \"decision\",\"confidence\",\n",
        "        \"cognitive_score\",\"personality\",\"timestamp\"\n",
        "    ])\n",
        "\n",
        "# ================= MODEL UTILS =================\n",
        "def load_user(username):\n",
        "    model = NeuroTwin()\n",
        "    path = f\"{USER_DIR}/{username}.pth\"\n",
        "\n",
        "    if os.path.exists(path):\n",
        "        model.load_state_dict(torch.load(path, map_location=\"cpu\"))\n",
        "    else:\n",
        "        model.load_state_dict(torch.load(BASE_MODEL, map_location=\"cpu\"))\n",
        "        torch.save(model.state_dict(), path)\n",
        "\n",
        "    return model, path\n",
        "\n",
        "def model_vector(model):\n",
        "    return np.concatenate([p.detach().numpy().flatten() for p in model.parameters()])\n",
        "\n",
        "# ================= PREDICT + TABLE UPDATE =================\n",
        "def predict_and_update(name, age, df,\n",
        "                       risk, time_p, reward, mood, prev_loss, rt):\n",
        "\n",
        "    if not name.strip():\n",
        "        return df, df, \"‚ùå Name required\", \"\", \"\", \"\"\n",
        "\n",
        "    model,_ = load_user(name)\n",
        "    model.eval()\n",
        "\n",
        "    seq = torch.tensor([[[risk,time_p,reward,mood,prev_loss,rt]]*5],\n",
        "                       dtype=torch.float32)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        decision_prob, confidence = model(seq)\n",
        "\n",
        "    decision = \"ACCEPT\" if decision_prob.item() > 0.5 else \"REJECT\"\n",
        "\n",
        "    # Cognitive score logic\n",
        "    base_score = 0.6\n",
        "    cognitive_score = (\n",
        "        base_score + confidence.item()*0.3\n",
        "        if decision == \"ACCEPT\"\n",
        "        else base_score - confidence.item()*0.3\n",
        "    )\n",
        "    cognitive_score = round(float(np.clip(cognitive_score,0,1)),3)\n",
        "\n",
        "    personality = (\n",
        "        \"INTJ\" if decision==\"ACCEPT\" and risk<0.5 else\n",
        "        \"ENFP\" if decision==\"ACCEPT\" else\n",
        "        \"ISTJ\"\n",
        "    )\n",
        "\n",
        "    entry = {\n",
        "        \"user_id\": f\"U{len(df)+1:03d}\",\n",
        "        \"name\": name,\n",
        "        \"age\": age,\n",
        "        \"decision\": decision,\n",
        "        \"confidence\": round(confidence.item()*100,2),\n",
        "        \"cognitive_score\": cognitive_score,\n",
        "        \"personality\": personality,\n",
        "        \"timestamp\": datetime.now().strftime(\"%H:%M:%S\")\n",
        "    }\n",
        "\n",
        "    df = pd.concat([df, pd.DataFrame([entry])], ignore_index=True)\n",
        "\n",
        "    return (\n",
        "        df,\n",
        "        df,\n",
        "        \"‚úÖ Decision stored in table\",\n",
        "        decision,\n",
        "        f\"{entry['confidence']}%\",\n",
        "        personality\n",
        "    )\n",
        "\n",
        "# ================= BRAIN DRIFT =================\n",
        "def brain_drift(username):\n",
        "    model,_ = load_user(username)\n",
        "    vec = model_vector(model)\n",
        "\n",
        "    hist_path = f\"{USER_DIR}/{username}_history.npy\"\n",
        "    history = np.load(hist_path) if os.path.exists(hist_path) else np.array([vec])\n",
        "\n",
        "    drift=[np.linalg.norm(vec-h) for h in history]\n",
        "    history=np.vstack([history,vec])\n",
        "    np.save(hist_path,history)\n",
        "\n",
        "    fig,ax=plt.subplots()\n",
        "    ax.plot(drift,marker=\"o\")\n",
        "    ax.set_title(\"Brain Drift Over Time\")\n",
        "    ax.set_xlabel(\"Updates\")\n",
        "    ax.set_ylabel(\"Drift\")\n",
        "    return fig\n",
        "\n",
        "# ================= SIMILARITY =================\n",
        "def similarity_users(u1,u2):\n",
        "    m1,_=load_user(u1)\n",
        "    m2,_=load_user(u2)\n",
        "    sim=cosine_similarity([model_vector(m1)],[model_vector(m2)])[0][0]\n",
        "    return f\"Similarity: {round(sim*100,2)}%\"\n",
        "\n",
        "# ================= CLUSTERING =================\n",
        "def cluster_users(df):\n",
        "    if len(df)<2:\n",
        "        return \"Need ‚â•2 records\"\n",
        "\n",
        "    X=df[[\"cognitive_score\"]]\n",
        "    labels=KMeans(n_clusters=2,n_init=10).fit_predict(X)\n",
        "\n",
        "    out=df.copy()\n",
        "    out[\"cluster\"]=labels\n",
        "    return out[[\"name\",\"decision\",\"cluster\"]]\n",
        "\n",
        "# ================= UI =================\n",
        "with gr.Blocks(title=\"üß† NeuroTwin Cognitive System\") as demo:\n",
        "\n",
        "    gr.Markdown(\"# üß† NeuroTwin ‚Äì Decision-Driven Cognitive Twin\")\n",
        "\n",
        "    state_df = gr.State(init_state())\n",
        "\n",
        "    with gr.Row():\n",
        "        name = gr.Textbox(label=\"Name\")\n",
        "        age = gr.Number(label=\"Age\",value=20)\n",
        "\n",
        "    gr.Markdown(\"## üß† Decision Inputs\")\n",
        "    risk=gr.Slider(0,1,0.5,label=\"Risk\")\n",
        "    time_p=gr.Slider(0,1,0.5,label=\"Time Pressure\")\n",
        "    reward=gr.Slider(0,1,0.5,label=\"Reward\")\n",
        "    mood=gr.Slider(0,1,0.5,label=\"Stress\")\n",
        "    prev_loss=gr.Radio([0,1],value=0,label=\"Previous Loss\")\n",
        "    rt=gr.Slider(0.5,4,1.5,label=\"Reaction Time\")\n",
        "\n",
        "    decision=gr.Textbox(label=\"Decision\")\n",
        "    confidence=gr.Textbox(label=\"Confidence\")\n",
        "    personality=gr.Textbox(label=\"Personality\")\n",
        "\n",
        "    status=gr.Textbox(label=\"Status\",interactive=False)\n",
        "    table=gr.Dataframe(interactive=False)\n",
        "\n",
        "    gr.Button(\"üß† Make Decision\").click(\n",
        "        predict_and_update,\n",
        "        [name,age,state_df,risk,time_p,reward,mood,prev_loss,rt],\n",
        "        [state_df,table,status,decision,confidence,personality]\n",
        "    )\n",
        "\n",
        "    gr.Markdown(\"## üìà Brain Drift\")\n",
        "    gr.Button(\"Show Brain Drift\").click(brain_drift,name,gr.Plot())\n",
        "\n",
        "    gr.Markdown(\"## üîÅ Cognitive Similarity\")\n",
        "    gr.Button(\"Compare With Self\").click(similarity_users,[name,name],gr.Textbox())\n",
        "\n",
        "    gr.Markdown(\"## üß© Personality Clustering\")\n",
        "    gr.Button(\"Cluster Records\").click(cluster_users,state_df,gr.Dataframe())\n",
        "\n",
        "demo.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        },
        "id": "J-oKQ6ukc0E8",
        "outputId": "d1745c66-5aaf-4ff6-f46d-6fb4e0d16757"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://4a6fc66dfe100e039e.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://4a6fc66dfe100e039e.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    }
  ]
}